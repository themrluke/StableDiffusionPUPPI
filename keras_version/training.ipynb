{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"4\">\n",
    "Use this training notebook to train UNet_lite or UNet2d from: <br> \n",
    "<code><font size=\"3.5\">\n",
    "Models/models_large.py <br>\n",
    "Models/models_reduced_constkernels.py <br>\n",
    "Models/models_reduced_doublingkernels.py <br>\n",
    "</font></code> as it works with their architecture and subclassing API. <br><br>\n",
    "Change as required for your setup:\n",
    "<ul>\n",
    "  <li><code>gpu = gpus[#GPU]</code> Choose #GPU to run training on, can copy and paste notebook and train on different GPUs simultaneously</li>\n",
    "  <li><code>data_dir =</code> Specify path to .root files</li>\n",
    "  <li><code>num_events = </code> How many events to load to .npy and/or train on</li>\n",
    "  <li><code>dataset = Dataset(..., save = True/False,...</code> Use True for 1st run through to create .npy files, False after </li>\n",
    "  <li><code>saturation_value = </code> Choose saturation value</li>\n",
    "  <li><code>output_dir= </code>set where you want your trained model to be saved</li>\n",
    "  <li><code>from Models.</code> FILE </code><code> import ModelConfig, TrainingConfig</code>  Specify FILE of which model architecture from list of .py files above</li>\n",
    "  <li><code>modtype = </code> Choose from either 'UNet_lite' or 'UNet2d'</li>\n",
    "  <li><code>strip_size = </code> Choose from either 'strip' or 'full_image'</li>\n",
    "</ul>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 19:00:17.750988: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "INFO:numexpr.utils:Note: detected 128 virtual cores but NumExpr set to maximum of 64, check \"NUMEXPR_MAX_THREADS\" environment variable.\n",
      "INFO:numexpr.utils:Note: NumExpr detected 128 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Number of available GPUs: 6\n",
      "Current GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm # Library used to display progress bars for loops, making it easy to track the progress of an iteration\n",
    "from data_processing import Dataset\n",
    "from noise import NoiseScheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "\n",
    "\n",
    "seed = 22\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Set the device to custom GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "gpu = gpus[0] # Specify which gpu to use here. Can run multiple scripts on different GPUs\n",
    "if gpu:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        tf.config.experimental.set_visible_devices(gpu, 'GPU')\n",
    "        print(\"CUDA is available!\")\n",
    "        print(\"Number of available GPUs:\", len(gpus))\n",
    "        print(\"Current GPU:\", gpu)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to directory where data is stored\n",
    "work_home = False\n",
    "data_dir = \"Datasets\" if work_home else \"/cephfs/dice/projects/L1T/diffusion/datasets/\"\n",
    "\n",
    "num_events = 50000 # Adjust number of events to train model here\n",
    "start_idx = 0\n",
    "end_idx = num_events\n",
    "dataset = Dataset(num_events, (120, 72), signal_file=f\"{data_dir}/CaloImages_signal.root\", pile_up_file=f\"{data_dir}/CaloImages_bkg.root\", save=False, start_idx=start_idx, end_idx=end_idx) # Can set to 10000\n",
    "# 1000: number of samples in dataset\n",
    "# (120, 72): Shape of each data sample (eg. image with dimensions 120x72)\n",
    "# signal_file: Signal file for the dataset\n",
    "# pile_up_file: This file contains background/ pileup data for the dataset\n",
    "# save=False means the dataset should not be saved to disk after creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading .npy files from /storage/sa21722/stablediffusion/keras_version/signal.npy and /storage/sa21722/stablediffusion/keras_version/pile_up.npy\n"
     ]
    }
   ],
   "source": [
    "dataset() # once this is cached, you don't have to re-load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dim=(64,64) #resize each data sample image into 64x64 resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Re-sizing tensors...\n"
     ]
    }
   ],
   "source": [
    "saturation_value = 512 # Change saturation energy here\n",
    "dataset.preprocess(new_dim)\n",
    "# Pixels with an energy greater than the first number (eg.16 or 64 etc) will be clipped and shown as this number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract horizontal strip from y=26 to y=38 (12 pixels tall)\n",
    "# Change how much of image to train model on here\n",
    "strip_size = 'full_image'\n",
    "\n",
    "if strip_size == 'full_image':\n",
    "    y_start = 0\n",
    "    y_end = 64\n",
    "\n",
    "elif strip_size == 'strip':\n",
    "    y_start = 26\n",
    "    y_end = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 19:00:26.065588: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 19:00:26.322814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13764 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 64, 64, 1)\n",
      "<dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "# Convert data to TensorFlow tensors\n",
    "clean_frames = tf.convert_to_tensor(dataset.signal, dtype=tf.float32)[:, y_start:y_end, :]\n",
    "pile_up = tf.convert_to_tensor(dataset.pile_up, dtype=tf.float32)[:, y_start:y_end, :]\n",
    "\n",
    "# Normalize data\n",
    "clean_frames = tf.clip_by_value(clean_frames, 0, saturation_value)\n",
    "pile_up = tf.clip_by_value(pile_up, 0, saturation_value)\n",
    "\n",
    "# Reshape data\n",
    "clean_frames = tf.expand_dims(clean_frames, axis=-1)\n",
    "pile_up = tf.expand_dims(pile_up, axis=-1)\n",
    "\n",
    "print(clean_frames.shape)\n",
    "print(clean_frames.dtype)\n",
    "# Permute changes the order to (B, H, W, C)\n",
    "# This is done to match the common image representation format where the last dimension is the number of channels (e.g., RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataLoader object for the clean_frames dataset\n",
    "# batch_size determines how many samples will be processed together in each iteration during training or evaluation.\n",
    "batch_size = 16\n",
    "#dataloader = tf.data.Dataset.from_tensor_slices(clean_frames).batch(batch_size)\n",
    "dataloader = (\n",
    "    tf.data.Dataset.from_tensor_slices(clean_frames)\n",
    "    .shuffle(buffer_size=len(clean_frames))\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 19:00:28.758816: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8902\n",
      "2024-07-31 19:00:28.836752: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNetLite_hls\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " positional_encoding (Positi  multiple                 0         \n",
      " onalEncoding)                                                   \n",
      "                                                                 \n",
      " relu (ReLU)                 multiple                  0         \n",
      "                                                                 \n",
      " emb1 (Dense)                multiple                  5         \n",
      "                                                                 \n",
      " convd1_1 (Conv2D)           multiple                  36        \n",
      "                                                                 \n",
      " normd1_1 (LayerNormalizatio  multiple                 8         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " convd1_2 (Conv2D)           multiple                  144       \n",
      "                                                                 \n",
      " normd1_2 (LayerNormalizatio  multiple                 8         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " pool3 (Conv2D)              multiple                  144       \n",
      "                                                                 \n",
      " normb1_1 (LayerNormalizatio  multiple                 8         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " emb4 (Dense)                multiple                  20        \n",
      "                                                                 \n",
      " convb1_1 (Conv2D)           multiple                  288       \n",
      "                                                                 \n",
      " normb1_2 (LayerNormalizatio  multiple                 16        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " convb1_2 (Conv2D)           multiple                  576       \n",
      "                                                                 \n",
      " normb1_3 (LayerNormalizatio  multiple                 16        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " up1 (Conv2DTranspose)       multiple                  292       \n",
      "                                                                 \n",
      " normu1_1 (LayerNormalizatio  multiple                 8         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " emb5 (Dense)                multiple                  40        \n",
      "                                                                 \n",
      " convu1_1 (Conv2D)           multiple                  288       \n",
      "                                                                 \n",
      " normu1_2 (LayerNormalizatio  multiple                 8         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " convu1_1 (Conv2D)           multiple                  144       \n",
      "                                                                 \n",
      " normu1_2 (LayerNormalizatio  multiple                 8         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " out (Conv2D)                multiple                  5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,062\n",
      "Trainable params: 2,062\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from Models.models_reduced_doublingkernels import Model, TrainingConfig\n",
    "\n",
    "modtype = 'UNet_lite' # Change Model type here\n",
    "model = Model(modtype, new_dim)\n",
    "model = model.__getitem__()\n",
    "\n",
    "if modtype == 'UNet2d':\n",
    "    config = TrainingConfig(output_dir='retrained_models_UNet2d/temp') # Holds parameters used for training the model eg. learning rate, image size, number of epochs ....\n",
    "\n",
    "elif modtype == 'UNet_lite':\n",
    "    config = TrainingConfig(output_dir='trained_models_lite/temp') # Holds parameters used for training the model eg. learning rate, image size, number of epochs ....\n",
    "\n",
    "\n",
    "# Verify model initialization\n",
    "dummy_input = tf.zeros((1, 64, 64, 1), dtype=tf.float32)\n",
    "dummy_time = tf.zeros((), dtype=tf.int32)\n",
    "model([dummy_input, dummy_time])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learning rate schedule\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate=config.learning_rate,\n",
    "    decay_steps=len(dataloader) * config.num_epochs,\n",
    "    alpha=0.0\n",
    ")\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(reduce_retracing=True)\n",
    "def train_step(model, optimizer, noisy_images, noise_added, timestep, loss_fn, saturation_value, modtype):\n",
    "    # Apply saturation value clipping and scaling\n",
    "    noisy_images = tf.clip_by_value(noisy_images, 0, saturation_value)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Predict the noise residual\n",
    "        if modtype == 'UNet2d':\n",
    "            noise_pred = model([noisy_images, timestep], training=True)[0]\n",
    "        elif modtype == 'UNet_lite':\n",
    "            noise_pred = model([noisy_images, timestep], training=True)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = loss_fn(noise_added, noise_pred)\n",
    "    \n",
    "    # Compute gradients\n",
    "    grads = tape.gradient(loss, model.trainable_weights)\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def train_loop(config, model, noise_sample, optimizer, train_dataloader, noise_scheduler, n_events, loss_fn, saturation_value, modtype):\n",
    "\n",
    "    global_step = 0  # Counter to keep track of the number of steps taken during training\n",
    "    \n",
    "    # Loop over epochs\n",
    "    for epoch in range(config.num_epochs):\n",
    "        progress_bar = tqdm(total=len(train_dataloader))\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "        # Iterate over each batch in the training DataLoader\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            timestep = tf.random.uniform((), minval=0, maxval=config.num_train_timesteps, dtype=tf.int32)\n",
    "            random_seed = np.random.randint(0, n_events)\n",
    "            \n",
    "            noisy_images, noise_added = noise_scheduler.add_noise(\n",
    "                clean_frame=batch, \n",
    "                noise_sample=noise_sample, \n",
    "                timestep=timestep, \n",
    "                random_seed=random_seed, \n",
    "                n_events=n_events\n",
    "            )\n",
    "            \n",
    "            # Perform the training step\n",
    "            loss = train_step(model, optimizer, noisy_images, noise_added, timestep, loss_fn, saturation_value, modtype)\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.update(1)\n",
    "            logs = {\"loss\": loss.numpy(), \"lr\": optimizer.learning_rate.numpy(), \"step\": global_step}\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            global_step += 1\n",
    "\n",
    "        # Save the model after each epoch\n",
    "        model.save_weights(os.path.join(config.output_dir, f\"model_epoch_{epoch}.h5\"))  # USE MODEL.SAVE() TO SAVE MODEL ARCHITECTURE ALSO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0a89c28dc346318c071c5963abd8a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 19:00:31.848382: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f84c473f050 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-31 19:00:31.848454: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-07-31 19:00:31.852588: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-31 19:00:31.913804: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-07-31 19:00:31.929398: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Running the training loop\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpile_up\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNoiseScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpile-up\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_events\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 47\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(config, model, noise_sample, optimizer, train_dataloader, noise_scheduler, n_events, loss_fn, saturation_value, modtype)\u001b[0m\n\u001b[1;32m     38\u001b[0m noisy_images, noise_added \u001b[38;5;241m=\u001b[39m noise_scheduler\u001b[38;5;241m.\u001b[39madd_noise(\n\u001b[1;32m     39\u001b[0m     clean_frame\u001b[38;5;241m=\u001b[39mbatch, \n\u001b[1;32m     40\u001b[0m     noise_sample\u001b[38;5;241m=\u001b[39mnoise_sample, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     n_events\u001b[38;5;241m=\u001b[39mn_events\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Perform the training step\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_added\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaturation_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Update progress bar\u001b[39;00m\n\u001b[1;32m     50\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/software/sa21722/miniconda3/envs/hls_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/software/sa21722/miniconda3/envs/hls_env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/software/sa21722/miniconda3/envs/hls_env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/software/sa21722/miniconda3/envs/hls_env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/software/sa21722/miniconda3/envs/hls_env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/software/sa21722/miniconda3/envs/hls_env/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/software/sa21722/miniconda3/envs/hls_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Running the training loop\n",
    "train_loop(config, model, pile_up, optimizer, dataloader, NoiseScheduler('pile-up'), num_events, loss_fn, saturation_value, modtype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
