Backend: Vivado
ClockPeriod: 2.78
HLSConfig:
  LayerName:
    add:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    add_1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    add_2:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convb1_1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convb1_1_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convb1_2:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convb1_2_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convd1_1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convd1_1_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convd1_2:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convd1_2_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convu1_1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convu1_1_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convu1_2:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convu1_2_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convu1_3:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    convu1_3_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    emb1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<3,0, AP_RND, AP_SAT>
        result: ap_fixed<3,1, AP_RND, AP_SAT>
        weight: ap_fixed<8,0, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    emb1_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    emb4:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<3,0, AP_RND, AP_SAT>
        result: ap_fixed<5,1, AP_RND, AP_SAT>
        weight: ap_fixed<9,1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    emb4_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    emb5:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<8,0, AP_RND, AP_SAT>
        result: ap_fixed<4,1, AP_RND, AP_SAT>
        weight: ap_fixed<10,2, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    emb5_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    input_images:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    normb1_1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        scale: fixed<16,6>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    normb1_2:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        scale: fixed<16,6>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    normb1_3:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        scale: fixed<16,6>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    normd1_1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        scale: fixed<16,6>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    normd1_2:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        scale: fixed<16,6>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    normu1_1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        scale: fixed<16,6>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    normu1_2:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        scale: fixed<16,6>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    normu1_3:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        scale: fixed<16,6>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    out:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    out_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    pool3:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    pool3_linear:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    pos_enc_bottleneck:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    pos_enc_main:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_2:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_3:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_4:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_5:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_6:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_7:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_8:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    relu_9:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
    up1:
      ParallelizationFactor: 16
      Precision:
        bias: ap_fixed<7, 2, AP_RND, AP_SAT>
        result: ap_fixed<30, 8, AP_RND, AP_SAT>
        weight: ap_fixed<13, 1, AP_RND, AP_SAT>
      ReuseFactor: 1
      Strategy: Latency
      Trace: true
  Model:
    BramFactor: 1000000000
    Precision: ap_fixed<30, 8, AP_RND, AP_SAT>
    ReuseFactor: 1
    Strategy: Latency
    TraceOutput: false
IOType: io_stream
InputData: null
KerasModel: !keras_model 'hls_outputs_inference/keras_model.h5'
OutputDir: hls_outputs_inference
OutputPredictions: null
Part: xcvu9p-flga2577-2-e
ProjectName: myproject
Stamp: AdcF59Cb
Version: 1.0.0
